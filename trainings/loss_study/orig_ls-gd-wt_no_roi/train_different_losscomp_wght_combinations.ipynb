{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-20 22:34:43.954786: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-20 22:34:44.021786: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-07-20 22:34:44.021868: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-07-20 22:34:44.024012: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-07-20 22:34:44.036171: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-20 22:34:45.410724: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib.patches import Circle\n",
    "import tf_silent\n",
    "from pinn import PINN\n",
    "from network import Network\n",
    "from optimizer_sep_losses import L_BFGS_B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-20 22:35:01.776818: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-20 22:35:01.898607: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-20 22:35:01.900312: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-20 22:35:01.910870: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-20 22:35:01.912646: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-20 22:35:01.914171: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-20 22:35:02.085184: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-20 22:35:02.087177: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-20 22:35:02.088592: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2025-07-20 22:35:02.088852: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-20 22:35:02.090226: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38893 MB memory:  -> device: 0, name: NVIDIA A40, pci bus id: 0000:1e:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[LogicalDevice(name='/device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_logical_devices(\"GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mass_cons(network, xy):\n",
    "    \"\"\"\n",
    "    Compute u_x and v_y\n",
    "    Args:\n",
    "        xy: network input variables as ndarray.\n",
    "    Returns:\n",
    "        (u_x, v_y) as ndarray.\n",
    "    \"\"\"\n",
    "\n",
    "    xy = tf.constant(xy)\n",
    "    x, y = [ xy[..., i, tf.newaxis] for i in range(xy.shape[-1]) ]\n",
    "    with tf.GradientTape(persistent=True) as g:\n",
    "      g.watch(x)\n",
    "      g.watch(y)\n",
    "\n",
    "      u_v_p = network(tf.concat([x, y], axis=-1))\n",
    "      u = u_v_p[..., 0, tf.newaxis]\n",
    "      v = u_v_p[..., 1, tf.newaxis]\n",
    "      p = u_v_p[..., 2, tf.newaxis]\n",
    "    u_x = g.batch_jacobian(u, x)[..., 0]\n",
    "    v_y = g.batch_jacobian(v, y)[..., 0]\n",
    "\n",
    "    return u_x.numpy(), v_y.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def u_0(xy):\n",
    "    \"\"\"\n",
    "    Initial wave form.\n",
    "    Args:\n",
    "        tx: variables (t, x) as tf.Tensor.\n",
    "    Returns:\n",
    "        u(t, x) as tf.Tensor.\n",
    "    \"\"\"\n",
    "\n",
    "    x = xy[..., 0, None]\n",
    "    y = xy[..., 1, None]\n",
    "\n",
    "\n",
    "    return    4*y*(1 - y) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# number of training samples\n",
    "num_train_samples = 4000\n",
    "# number of test samples\n",
    "num_test_samples = 400\n",
    "\n",
    "# inlet flow velocity\n",
    "u0 = 1\n",
    "# density\n",
    "rho = 1\n",
    "# viscosity\n",
    "mu = 2.5*1e-2\n",
    "# Re = (L*u0*rho)/mu ==> rho/mu = 40\n",
    "\n",
    "# Domain and circle data\n",
    "x_f =2\n",
    "x_ini=0\n",
    "y_f=1\n",
    "y_ini=0\n",
    "Cx = 0.5\n",
    "Cy = 0.5\n",
    "a = 0.1\n",
    "b = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xyt_circle = np.random.rand(num_train_samples, 2)\n",
    "xyt_circle[...,0] = 2*(a)*xyt_circle[...,0] +(Cx-a)\n",
    "xyt_circle[0:num_train_samples//2,1] = b*(1 - (xyt_circle[0:num_train_samples//2,0]-Cx)**2 / a**2)**0.5 + Cy\n",
    "xyt_circle[num_train_samples//2:,1] = -b*(1 - (xyt_circle[num_train_samples//2:,0]-Cx)**2 / a**2)**0.5 + Cy\n",
    "\n",
    "# create training input\n",
    "xyt_eqn = np.random.rand(num_train_samples, 2)\n",
    "xyt_eqn[...,0] = (x_f - x_ini)*xyt_eqn[...,0] + x_ini\n",
    "xyt_eqn[...,1] = (y_f - y_ini)*xyt_eqn[...,1] + y_ini\n",
    "\n",
    "corner_buffer = 0.05\n",
    "max_attempts = 100\n",
    "\n",
    "for i in range(num_train_samples):\n",
    "    attempts = 0\n",
    "    while True:\n",
    "        inside_cylinder = (xyt_eqn[i, 0] - Cx)**2 / a**2 + (xyt_eqn[i, 1] - Cy)**2 / b**2 < 1\n",
    "        near_corner = (\n",
    "            (xyt_eqn[i, 0] < x_ini + corner_buffer and xyt_eqn[i, 1] < y_ini + corner_buffer) or\n",
    "            (xyt_eqn[i, 0] < x_ini + corner_buffer and xyt_eqn[i, 1] > y_f - corner_buffer) or\n",
    "            (xyt_eqn[i, 0] > x_f - corner_buffer and xyt_eqn[i, 1] < y_ini + corner_buffer) or\n",
    "            (xyt_eqn[i, 0] > x_f - corner_buffer and xyt_eqn[i, 1] > y_f - corner_buffer)\n",
    "        )\n",
    "\n",
    "        if not (inside_cylinder or near_corner):\n",
    "            break\n",
    "\n",
    "        xyt_eqn[i, 0] = (x_f - x_ini) * np.random.rand() + x_ini\n",
    "        xyt_eqn[i, 1] = (y_f - y_ini) * np.random.rand() + y_ini\n",
    "\n",
    "        attempts += 1\n",
    "        if attempts > max_attempts:\n",
    "            print(f\"Warning: Max attempts reached for sample {i}\")\n",
    "            break  # Accept the current (possibly imperfect) point or skip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Sample in the annulus (r+0.2) region # annulus is a plane region between two concentric circles\n",
    "# num_annulus_samples = 1500\n",
    "# theta = np.random.uniform(0, 2*np.pi, num_annulus_samples)\n",
    "# r = np.sqrt(np.random.uniform(1, 9, num_annulus_samples))  # sqrt for uniform area\n",
    "# # circle eqn in polar coordinates: x = Cx + a * r * cos(theta), y = Cy + b * r * sin(theta)\n",
    "# x = Cx + a * r * np.cos(theta)\n",
    "# y = Cy + b * r * np.sin(theta)\n",
    "# xyt_annulus = np.stack([x, y], axis=1)\n",
    "\n",
    "# # Wake region\n",
    "# num_strip_samples = 2500\n",
    "# x_strip = np.random.uniform(0.6, 1.2, num_strip_samples)\n",
    "# y_strip = np.random.uniform(0.3, 0.7, num_strip_samples)\n",
    "# xyt_strip = np.stack([x_strip, y_strip], axis=1)\n",
    "\n",
    "# xyt_roi = np.concatenate([xyt_annulus, xyt_strip], axis=0)\n",
    "# num_interior_samples = xyt_roi.shape[0]\n",
    "\n",
    "xyt_w1 = np.random.rand(num_train_samples, 2)  # top-bottom boundaries\n",
    "xyt_w1[..., 0] = (x_f - x_ini)*xyt_w1[...,0] + x_ini\n",
    "xyt_w1[..., 1] =  y_ini          # y-position is 0 or 1\n",
    "num_w1_samples = xyt_w1.shape[0]\n",
    "\n",
    "xyt_w2 = np.random.rand(num_train_samples, 2)  # top-bottom boundaries\n",
    "xyt_w2[..., 0] = (x_f - x_ini)*xyt_w2[...,0] + x_ini\n",
    "xyt_w2[..., 1] =  y_f\n",
    "num_w2_samples = xyt_w2.shape[0]\n",
    "\n",
    "xyt_out = np.random.rand(num_train_samples, 2)  # left-right boundaries\n",
    "xyt_out[..., 0] = x_f\n",
    "num_out_samples = xyt_out.shape[0]\n",
    "\n",
    "xyt_in = np.random.rand(num_train_samples, 2)\n",
    "xyt_in[..., 0] = x_ini\n",
    "num_in_samples = xyt_in.shape[0]\n",
    "\n",
    "# Aggregate input data for training\n",
    "x_train = [\n",
    "    xyt_eqn,        # All interior points (PDE loss)\n",
    "    # xyt_roi,  # Region of interest (annulus + strip)\n",
    "    xyt_w1,            # Wall y=0\n",
    "    xyt_w2,            # Wall y=1\n",
    "    xyt_out,           # Outlet x=2\n",
    "    xyt_in,            # Inlet x=0\n",
    "    xyt_circle         # Cylinder boundary\n",
    "]\n",
    "# y_train: create outputs with respect to data shapes for each region\n",
    "zeros_interior = np.zeros((xyt_eqn.shape[0], 3))\n",
    "# zeros_roi = np.zeros((xyt_roi.shape[0], 3))\n",
    "zeros_w1 = np.zeros((xyt_w1.shape[0], 3))\n",
    "zeros_w2 = np.zeros((xyt_w2.shape[0], 3))\n",
    "zeros_out = np.zeros((xyt_out.shape[0], 3))\n",
    "zeros_circle = np.zeros((xyt_circle.shape[0], 3))\n",
    "\n",
    "# Inlet boundary condition (update shape)\n",
    "a = u_0(tf.constant(xyt_in)).numpy()\n",
    "b = np.zeros((xyt_in.shape[0], 1))\n",
    "onze = np.random.permutation(np.concatenate([a, b, a], axis=-1))\n",
    "\n",
    "y_train = [\n",
    "    zeros_interior,  # All interior points (PDE loss)\n",
    "    # zeros_roi,       # Region of interest (annulus + strip)\n",
    "    onze,            # Inlet x=0\n",
    "    zeros_w1,        # Wall y=0\n",
    "    zeros_w2,        # Wall y=1\n",
    "    zeros_out,       # Outlet x=2\n",
    "    zeros_circle     # Cylinder boundary\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shapes:\n",
      "Dimensions x: (x_cord, y_cord), y: (u, v, p)\n",
      "Shape of x: (4000, 2), Shape of y: (4000, 3)\n",
      "Shape of x: (4000, 2), Shape of y: (4000, 3)\n",
      "Shape of x: (4000, 2), Shape of y: (4000, 3)\n",
      "Shape of x: (4000, 2), Shape of y: (4000, 3)\n",
      "Shape of x: (4000, 2), Shape of y: (4000, 3)\n",
      "Shape of x: (4000, 2), Shape of y: (4000, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training data shapes:\")\n",
    "print(\"Dimensions x: (x_cord, y_cord), y: (u, v, p)\")\n",
    "for x, y in zip(x_train, y_train):\n",
    "    print(f\"Shape of x: {x.shape}, Shape of y: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...just the code as requested...\n",
    "loss_weight_combinations = [\n",
    "    [5, 1, 1, 1, 1, 5],\n",
    "    [6, 1, 1, 1, 1, 10],\n",
    "    [7, 1, 1, 1, 1, 15],\n",
    "    [8, 1, 1, 1, 1, 20],\n",
    "    [10, 1, 1, 1, 1, 30],\n",
    "    [15, 1, 1, 1, 1, 40],\n",
    "    [20, 1, 1, 1, 1, 50],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with weights #1: [5, 1, 1, 1, 1, 5] -> implicit_noroi_LC_eqn5cyl5\n",
      "Optimizer: L-BFGS-B (maxiter=30000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "L-BFGS-B:  44%|████▍     | 13272/30000 [30:45<38:45,  7.19iter/s, loss=0.0302]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 191ms/step\n",
      "Model implicit_noroi_LC_eqn5cyl5: Minimum u velocity in wake region = 0.0025\n",
      "\n",
      "Training with weights #2: [6, 1, 1, 1, 1, 10] -> implicit_noroi_LC_eqn6cyl10\n",
      "Optimizer: L-BFGS-B (maxiter=30000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "L-BFGS-B:  42%|████▏     | 12600/30000 [29:12<40:20,  7.19iter/s, loss=0.0307]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 114ms/step\n",
      "Model implicit_noroi_LC_eqn6cyl10: Minimum u velocity in wake region = 0.0024\n",
      "\n",
      "Training with weights #3: [7, 1, 1, 1, 1, 15] -> implicit_noroi_LC_eqn7cyl15\n",
      "Optimizer: L-BFGS-B (maxiter=30000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "L-BFGS-B:  47%|████▋     | 14045/30000 [32:16<36:40,  7.25iter/s, loss=0.0304] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 159ms/step\n",
      "Model implicit_noroi_LC_eqn7cyl15: Minimum u velocity in wake region = 0.0032\n",
      "\n",
      "Training with weights #4: [8, 1, 1, 1, 1, 20] -> implicit_noroi_LC_eqn8cyl20\n",
      "Optimizer: L-BFGS-B (maxiter=30000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "L-BFGS-B:  46%|████▌     | 13857/30000 [32:05<37:23,  7.20iter/s, loss=0.0307] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 107ms/step\n",
      "Model implicit_noroi_LC_eqn8cyl20: Minimum u velocity in wake region = -0.0005\n",
      "\n",
      "Training with weights #5: [10, 1, 1, 1, 1, 30] -> implicit_noroi_LC_eqn10cyl30\n",
      "Optimizer: L-BFGS-B (maxiter=30000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "L-BFGS-B:  47%|████▋     | 14107/30000 [31:01<34:56,  7.58iter/s, loss=0.0307] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 100ms/step\n",
      "Model implicit_noroi_LC_eqn10cyl30: Minimum u velocity in wake region = 0.0022\n",
      "\n",
      "Training with weights #6: [15, 1, 1, 1, 1, 40] -> implicit_noroi_LC_eqn15cyl40\n",
      "Optimizer: L-BFGS-B (maxiter=30000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "L-BFGS-B:  47%|████▋     | 14041/30000 [32:53<37:22,  7.12iter/s, loss=0.032]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 133ms/step\n",
      "Model implicit_noroi_LC_eqn15cyl40: Minimum u velocity in wake region = 0.0017\n",
      "\n",
      "Training with weights #7: [20, 1, 1, 1, 1, 50] -> implicit_noroi_LC_eqn20cyl50\n",
      "Optimizer: L-BFGS-B (maxiter=30000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "L-BFGS-B:  46%|████▋     | 13932/30000 [36:34<42:11,  6.35iter/s, loss=0.0426]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 223ms/step\n",
      "Model implicit_noroi_LC_eqn20cyl50: Minimum u velocity in wake region = -0.0067\n",
      "\n",
      " Best Manual Weight Run:\n",
      "loss_weights: [5.0, 1.0, 1.0, 1.0, 1.0, 5.0]\n",
      "final_loss: 0.03019734099507332\n",
      "min_u_wake: 0.0025\n",
      "model file: model_data/track_sep_losses/eqn5_cyl5/implicit_noroi_LC_eqn5cyl5.keras\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define wake box region\n",
    "a = 0.1  # radius of the cylinder\n",
    "x_start = 0.5 + a  # 0.6\n",
    "x_end = 1.2\n",
    "y_start = 0.5 - 0.15  # 0.4\n",
    "y_end = 0.5 + 0.15    # 0.6\n",
    "\n",
    "model_dir = 'model_data/track_sep_losses'\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "results = []\n",
    "\n",
    "for i, weights in enumerate(loss_weight_combinations):\n",
    "    cyl_weight = weights[-1]\n",
    "    eqn_weight = weights[0]\n",
    "    subdir = f'eqn{int(eqn_weight)}_cyl{int(cyl_weight)}'\n",
    "    run_dir = os.path.join(model_dir, subdir)\n",
    "    plot_dir = os.path.join(run_dir, 'plots')\n",
    "    os.makedirs(plot_dir, exist_ok=True)\n",
    "\n",
    "    model_name = f\"implicit_noroi_LC_eqn{eqn_weight}cyl{cyl_weight}\"\n",
    "    print(f\"\\nTraining with weights #{i+1}: {weights} -> {model_name}\")\n",
    "\n",
    "    # Reset network and PINN model\n",
    "    network = Network().build()\n",
    "    pinn = PINN(network, rho=rho, mu=mu).build()\n",
    "\n",
    "    # Setup optimizer\n",
    "    lbfgs = L_BFGS_B(\n",
    "        model=pinn,\n",
    "        x_train=x_train,\n",
    "        y_train=y_train,\n",
    "        factr=1e5,\n",
    "        m=50,\n",
    "        maxls=50,\n",
    "        maxiter=30000,\n",
    "        loss_weights=weights\n",
    "    )\n",
    "\n",
    "    # Train\n",
    "    lbfgs.fit()\n",
    "\n",
    "    # Save model\n",
    "    model_path = os.path.join(run_dir, f'{model_name}.keras')\n",
    "    network.save(model_path)\n",
    "\n",
    "    # Save loss history (npy only, remove redundant json saves)\n",
    "    np.save(os.path.join(run_dir, f'{model_name}_loss.npy'), np.array(lbfgs.tracker.losses))\n",
    "    np.save(os.path.join(run_dir, f'{model_name}_component_losses.npy'), np.array(lbfgs.tracker.component_losses))\n",
    "\n",
    "    final_loss = lbfgs.tracker.losses[-1] if lbfgs.tracker.losses else None\n",
    "\n",
    "    font1 = {'family': 'serif', 'size': 20}\n",
    "\n",
    "    # Inference mesh\n",
    "    x = np.linspace(x_ini, x_f, 300)\n",
    "    y = np.linspace(y_ini, y_f, 300)\n",
    "    x_grid, y_grid = np.meshgrid(x, y)\n",
    "    xy_flat = np.stack([x_grid.flatten(), y_grid.flatten()], axis=-1)\n",
    "\n",
    "    # Predict (u, v, p)\n",
    "    u_v_p = network.predict(xy_flat, batch_size=len(xy_flat))\n",
    "    u = u_v_p[..., 0].reshape(x_grid.shape)\n",
    "    v = u_v_p[..., 1].reshape(x_grid.shape)\n",
    "    p = u_v_p[..., 2].reshape(x_grid.shape)\n",
    "\n",
    "    # Create mask for points inside the wake box\n",
    "    mask = (x_grid >= x_start) & (x_grid <= x_end) & (y_grid >= y_start) & (y_grid <= y_end)\n",
    "    u_wake = u[mask]\n",
    "    min_u_wake = np.min(u_wake)\n",
    "    print(f\"Model {model_name}: Minimum u velocity in wake region = {min_u_wake:.4f}\")\n",
    "\n",
    "    # Save u contour plot\n",
    "    fig0, ax0 = plt.subplots(1, 1, figsize=(20, 8))\n",
    "    cf0 = ax0.contourf(x_grid, y_grid, u, np.arange(-0.5, 1.1, .02), extend='both', cmap='rainbow')\n",
    "    cbar0 = plt.colorbar(cf0)\n",
    "    ax0.add_patch(Circle((0.5, 0.5), 0.1, color=\"black\"))\n",
    "    plt.title(f\"{model_name}: u\", fontdict=font1)\n",
    "    plt.xlabel(\"x\", fontdict=font1)\n",
    "    plt.ylabel(\"y\", fontdict=font1)\n",
    "    plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "    cbar0.ax.tick_params(labelsize=15)\n",
    "    plt.tight_layout()\n",
    "    u_plot_path = os.path.join(plot_dir, f\"{model_name}_u.png\")\n",
    "    plt.savefig(u_plot_path, dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # Save streamlines plot\n",
    "    fig1, ax1 = plt.subplots(1, 1, figsize=(20, 8))\n",
    "    ax1.streamplot(x_grid, y_grid, u, v, color='k', density=5, linewidth=0.25)\n",
    "    ax1.add_patch(Circle((0.5, 0.5), 0.1, color=\"black\"))\n",
    "    plt.title(f\"{model_name}: Streamlines\", fontdict=font1)\n",
    "    plt.xlabel(\"x\", fontdict=font1)\n",
    "    plt.ylabel(\"y\", fontdict=font1)\n",
    "    plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "    plt.tight_layout()\n",
    "    stream_plot_path = os.path.join(plot_dir, f\"{model_name}_streamlines.png\")\n",
    "    plt.savefig(stream_plot_path, dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # Save a summary for this run (convert to python types for JSON)\n",
    "    summary_path = os.path.join(run_dir, f'{model_name}_training_summary.json')\n",
    "    summary = {\n",
    "        'loss_weights': [float(w) for w in weights],\n",
    "        'final_loss': float(final_loss) if final_loss is not None else None,\n",
    "        'min_u_wake': float(min_u_wake),\n",
    "        'model_filename': str(model_path),\n",
    "        'u_plot': str(u_plot_path),\n",
    "        'streamline_plot': str(stream_plot_path)\n",
    "    }\n",
    "    with open(summary_path, 'w') as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "\n",
    "    results.append(summary)\n",
    "\n",
    "# Save full summary for all runs\n",
    "with open(os.path.join(model_dir, 'all_training_summary_2.json'), 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "# Print best run\n",
    "best_run = min(results, key=lambda x: x['final_loss'])\n",
    "print(\"\\n Best Manual Weight Run:\")\n",
    "print(f\"loss_weights: {best_run['loss_weights']}\")\n",
    "print(f\"final_loss: {best_run['final_loss']}\")\n",
    "print(f\"min_u_wake: {best_run['min_u_wake']:.4f}\")\n",
    "print(f\"model file: {best_run['model_filename']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load tracked optimization data and plot with log scaling\n",
    "\n",
    "# losses = np.load('model_data/track_orig/loss_history.npy')\n",
    "# grads = np.load('model_data/track_orig/grad_history.npy')\n",
    "# weights = np.load('model_data/track_orig/weight_history.npy')\n",
    "\n",
    "# grad_norms = np.linalg.norm(grads, axis=1)\n",
    "# weight_norms = np.linalg.norm(weights, axis=1)\n",
    "\n",
    "# plt.figure(figsize=(12, 4))\n",
    "# plt.subplot(1, 3, 1)\n",
    "# plt.plot(losses)\n",
    "# plt.yscale('log')\n",
    "# plt.title('Loss (log scale)')\n",
    "# plt.xlabel('Iteration')\n",
    "# plt.ylabel('Loss')\n",
    "\n",
    "# plt.subplot(1, 3, 2)\n",
    "# plt.plot(grad_norms)\n",
    "# plt.yscale('log')\n",
    "# plt.title('Gradient Norm (log scale)')\n",
    "# plt.xlabel('Iteration')\n",
    "# plt.ylabel('Norm')\n",
    "\n",
    "# plt.subplot(1, 3, 3)\n",
    "# plt.plot(weight_norms)\n",
    "# plt.yscale('log')\n",
    "# plt.title('Weight Norm (log scale)')\n",
    "# plt.xlabel('Iteration')\n",
    "# plt.ylabel('Norm')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_profiles(x, y, u, v, cross_sections):\n",
    "    \"\"\"\n",
    "    Plot velocity profiles (u, v) along specified cross-sections.\n",
    "    Args:\n",
    "        x: x-array (meshgrid).\n",
    "        y: y-array (meshgrid).\n",
    "        u: u-array (velocity in x-direction).\n",
    "        v: v-array (velocity in y-direction).\n",
    "        cross_sections: List of cross-sections to plot. Each cross-section is a tuple (type, value).\n",
    "                        'type' can be 'x' or 'y', and 'value' is the coordinate value.\n",
    "                        Example: [('x', 0), ('y', 0), ('y', 1), ('x', 0.75)]\n",
    "    \"\"\"\n",
    "    for section in cross_sections:\n",
    "        section_type, value = section\n",
    "        if section_type == 'x':  # Vertical line (constant x)\n",
    "            idx = np.argmin(np.abs(x[0, :] - value))  # Find the closest x index\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.plot(y[:, idx], u[:, idx], label='u (x={})'.format(value))\n",
    "            plt.plot(y[:, idx], v[:, idx], label='v (x={})'.format(value))\n",
    "            plt.xlabel('y')\n",
    "            plt.ylabel('Velocity')\n",
    "            plt.title('Velocity Profiles at x = {}'.format(value))\n",
    "            plt.legend()\n",
    "            plt.grid()\n",
    "            plt.show()\n",
    "        elif section_type == 'y':  # Horizontal line (constant y)\n",
    "            idx = np.argmin(np.abs(y[:, 0] - value))  # Find the closest y index\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.plot(x[idx, :], u[idx, :], label='u (y={})'.format(value))\n",
    "            plt.plot(x[idx, :], v[idx, :], label='v (y={})'.format(value))\n",
    "            plt.xlabel('x')\n",
    "            plt.ylabel('Velocity')\n",
    "            plt.title('Velocity Profiles at y = {}'.format(value))\n",
    "            plt.legend()\n",
    "            plt.grid()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create meshgrid coordinates (x, y) for test plots    \n",
    "\n",
    "x = np.linspace(x_ini, x_f, num_test_samples)\n",
    "y = np.linspace(y_ini, y_f, num_test_samples)\n",
    "x, y = np.meshgrid(x, y)\n",
    "xy = np.stack([x.flatten(), y.flatten()], axis=-1)\n",
    "# predict (psi, p)\n",
    "u_v_p = network.predict(xy, batch_size=len(xy))\n",
    "u, v, p = [ u_v_p[..., i].reshape(x.shape) for i in range(u_v_p.shape[-1]) ]\n",
    "# compute (u, v)\n",
    "u = u.reshape(x.shape)\n",
    "v = v.reshape(x.shape)\n",
    "p = p.reshape(x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u.shape, v.shape, p.shape, x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contour(x, y, z, title, levels=200):\n",
    "    \"\"\"\n",
    "    Contour plot.\n",
    "    Args:\n",
    "        x: x-array.\n",
    "        y: y-array.\n",
    "        z: z-array.\n",
    "        title: title string.\n",
    "        levels: number of contour lines.\n",
    "        circle_center: (x, y) center of the circle.\n",
    "        circle_radius: radius of the circle.\n",
    "    \"\"\"\n",
    "    circle_center = (0.5, 0.5)\n",
    "    circle_radius = 0.1\n",
    "    vmin = np.min(z)\n",
    "    vmax = np.max(z)\n",
    "    font1 = {'family':'serif','size':20}\n",
    "    plt.contour(x, y, z, colors='k', linewidths=0.2, levels=levels)\n",
    "    plt.contourf(x, y, z, cmap='rainbow', levels=levels, norm=Normalize(vmin=vmin, vmax=vmax))\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect('equal')\n",
    "    circle = plt.Circle(circle_center, circle_radius, fc='black', zorder=10)\n",
    "    ax.add_patch(circle)\n",
    "    plt.title(title, fontdict=font1)\n",
    "    plt.xlabel(\"x\", fontdict=font1)\n",
    "    plt.ylabel(\"y\", fontdict=font1)\n",
    "    plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "    cbar = plt.colorbar(pad=0.03, aspect=25, format='%.0e')\n",
    "    cbar.mappable.set_clim(vmin, vmax)\n",
    "    cbar.ax.tick_params(labelsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # plot test results\n",
    "# fig = plt.figure(figsize=(16, 8))\n",
    "# contour(x, y, p, 'p')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# fig = plt.figure(figsize=(16, 8))\n",
    "# contour(x, y, u, 'u')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# fig = plt.figure(figsize=(16, 8))\n",
    "# contour(x, y, v, 'v')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "###########################\n",
    "from matplotlib.patches import Circle\n",
    "font1 = {'family':'serif','size':20}\n",
    "\n",
    "fig0, ax0 = plt.subplots(1, 1,figsize=(20,8))\n",
    "cf0 = ax0.contourf(x, y, p, np.arange(-0.2, 1, .02),\n",
    "                extend='both',cmap='rainbow')\n",
    "cbar0 = plt.colorbar(cf0, pad=0.03, aspect=25, format='%.0e')\n",
    "plt.title(\"p\", fontdict = font1)\n",
    "plt.xlabel(\"x\", fontdict = font1)\n",
    "plt.ylabel(\"y\", fontdict = font1)\n",
    "ax0.add_patch(Circle((0.5, 0.5), 0.1,color=\"black\"))\n",
    "plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "cbar0.ax.tick_params(labelsize=15)\n",
    "plt.show()\n",
    "\n",
    "###########################\n",
    "\n",
    "fig0, ax0 = plt.subplots(1, 1, figsize=(20,8))\n",
    "cf0 = ax0.contourf(x, y, u, np.arange(-0.5, 1.1, .02),\n",
    "                extend='both',cmap='rainbow')\n",
    "cbar0 = plt.colorbar(cf0, )\n",
    "plt.title(\"u\", fontdict = font1)\n",
    "plt.xlabel(\"x\", fontdict = font1)\n",
    "plt.ylabel(\"y\", fontdict = font1)\n",
    "ax0.add_patch(Circle((0.5, 0.5), 0.1,color=\"black\"))\n",
    "plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "cbar0.ax.tick_params(labelsize=15)\n",
    "plt.show()\n",
    "\n",
    "###########################\n",
    "\n",
    "fig0, ax0 = plt.subplots(1, 1,figsize=(20,8))\n",
    "cf0 = ax0.contourf(x, y, v, np.arange(-0.4, 0.4, .02),\n",
    "                extend='both',cmap='rainbow')\n",
    "cbar0 = plt.colorbar(cf0, pad=0.03, aspect=25, format='%.0e')\n",
    "plt.title(\"v\", fontdict = font1)\n",
    "plt.xlabel(\"x\", fontdict = font1)\n",
    "plt.ylabel(\"y\", fontdict = font1)\n",
    "ax0.add_patch(Circle((0.5, 0.5), 0.1,color=\"black\"))\n",
    "plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "cbar0.ax.tick_params(labelsize=15)\n",
    "plt.show()\n",
    "\n",
    "############################ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Circle\n",
    "\n",
    "font1 = {'family':'serif','size':20}\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(20, 8))\n",
    "# Contourf for pressure (or any scalar field)\n",
    "# cf = ax.contourf(x, y, u, np.arange(-0.2, 1, .02), extend='both', cmap='rainbow')\n",
    "# cbar = plt.colorbar(cf, pad=0.03, aspect=25, format='%.0e')\n",
    "# Streamlines for velocity field\n",
    "strm = ax.streamplot(x, y, u, v, color='k', density=10, linewidth=0.25)\n",
    "# Add cylinder\n",
    "ax.add_patch(Circle((0.5, 0.5), 0.1, color=\"black\"))\n",
    "plt.title(\"u with Streamlines (Re40)\", fontdict=font1)\n",
    "plt.xlabel(\"x\", fontdict=font1)\n",
    "plt.ylabel(\"y\", fontdict=font1)\n",
    "plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "# cbar.ax.tick_params(labelsize=15)\n",
    "# plt.savefig('u_streamlinesonly_Re40_opd.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Circle\n",
    "\n",
    "font1 = {'family':'serif','size':20}\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(20, 8))\n",
    "# Contourf for pressure (or any scalar field)\n",
    "# cf = ax.contourf(x, y, u, np.arange(-0.2, 1, .02), extend='both', cmap='rainbow')\n",
    "# cbar = plt.colorbar(cf, pad=0.03, aspect=25, format='%.0e')\n",
    "# Streamlines for velocity field\n",
    "strm = ax.streamplot(x, y, u, v, color='k', density=10, linewidth=0.25)\n",
    "# Add cylinder\n",
    "# ax.add_patch(Circle((0.5, 0.5), 0.1, color=\"black\"))\n",
    "plt.title(\"u with Streamlines (Re40)\", fontdict=font1)\n",
    "plt.xlabel(\"x\", fontdict=font1)\n",
    "plt.ylabel(\"y\", fontdict=font1)\n",
    "plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "# cbar.ax.tick_params(labelsize=15)\n",
    "# plt.savefig('u_streamlinesonly_Re40_opd.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Circle\n",
    "\n",
    "font1 = {'family':'serif','size':20}\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(20, 8))\n",
    "# Contourf for pressure (or any scalar field)\n",
    "cf = ax.contourf(x, y, u, np.arange(-0.2, 1, .02), extend='both', cmap='rainbow')\n",
    "cbar = plt.colorbar(cf, pad=0.03, aspect=25, format='%.0e')\n",
    "# Streamlines for velocity field\n",
    "strm = ax.streamplot(x, y, u, v, color='k', density=10, linewidth=0.25)\n",
    "# Add cylinder\n",
    "ax.add_patch(Circle((0.5, 0.5), 0.1, color=\"black\"))\n",
    "plt.title(\"u with Streamlines (Re40)\", fontdict=font1)\n",
    "plt.xlabel(\"x\", fontdict=font1)\n",
    "plt.ylabel(\"y\", fontdict=font1)\n",
    "plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "# cbar.ax.tick_params(labelsize=15)\n",
    "# plt.savefig('u_streamlines_Re40.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_profiles(x, y, u, v, cross_sections, save_csv=False, prefix=\"u10\", location=\"data/pinn_profiles/\"):\n",
    "    \"\"\"\n",
    "    Plot velocity profiles (u, v) along specified cross-sections and optionally save u profiles to CSV.\n",
    "    Args:\n",
    "        x: x-array (meshgrid).\n",
    "        y: y-array (meshgrid).\n",
    "        u: u-array (velocity in x-direction).\n",
    "        v: v-array (velocity in y-direction).\n",
    "        cross_sections: List of cross-sections to plot. Each cross-section is a tuple (type, value).\n",
    "        save_csv: If True, save u profiles to CSV files.\n",
    "        prefix: Prefix for CSV filenames.\n",
    "    \"\"\"\n",
    "    for section in cross_sections:\n",
    "        section_type, value = section\n",
    "        if section_type == 'x':  # Vertical line (constant x)\n",
    "            idx = np.argmin(np.abs(x[0, :] - value))  # Find the closest x index\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.plot(y[:, idx], u[:, idx], label='u (x={})'.format(value))\n",
    "            plt.plot(y[:, idx], v[:, idx], label='v (x={})'.format(value))\n",
    "            plt.xlabel('y')\n",
    "            plt.ylabel('Velocity')\n",
    "            plt.title('Velocity Profiles at x = {}'.format(value))\n",
    "            plt.legend()\n",
    "            plt.grid()\n",
    "            plt.show()\n",
    "            if save_csv:\n",
    "                # Save u profile: y as 'x', u as 'u'\n",
    "                df = pd.DataFrame({'x': y[:, idx], 'u': u[:, idx]})\n",
    "                filename = f\"{prefix}_{value}.csv\"\n",
    "                df.to_csv(location+prefix+\"/\"+filename, index=False)\n",
    "        elif section_type == 'y':  # Horizontal line (constant y)\n",
    "            idx = np.argmin(np.abs(y[:, 0] - value))  # Find the closest y index\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.plot(x[idx, :], u[idx, :], label='u (y={})'.format(value))\n",
    "            plt.plot(x[idx, :], v[idx, :], label='v (y={})'.format(value))\n",
    "            plt.xlabel('x')\n",
    "            plt.ylabel('Velocity')\n",
    "            plt.title('Velocity Profiles at y = {}'.format(value))\n",
    "            plt.legend()\n",
    "            plt.grid()\n",
    "            plt.show()\n",
    "            if save_csv:\n",
    "                # Save u profile: x as 'x', u as 'u'\n",
    "                df = pd.DataFrame({'x': x[idx, :], 'u': u[idx, :]})\n",
    "                filename = f\"{prefix}_y{value}.csv\"\n",
    "                df.to_csv(location+prefix+\"/\"+filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot velocity profiles along specified cross-sections\n",
    "import pandas as pd\n",
    "cross_sections = [\n",
    "    ('x', 0.30),\n",
    "    ('x', 0.35),\n",
    "    ('x', 0.40),\n",
    "    ('x', 0.45),\n",
    "    ('x', 0.50),\n",
    "    ('x', 0.55),\n",
    "    ('x', 0.60),\n",
    "    ('x', 0.61),\n",
    "    ('x', 0.62),\n",
    "    ('x', 0.63),\n",
    "    ('x', 0.64),\n",
    "    ('x', 0.65),\n",
    "    ('x', 0.70),\n",
    "    ('x', 0.75),\n",
    "]\n",
    "plot_profiles(x, y, u, v, cross_sections, save_csv=True, prefix=\"u40_opt\", location=\"data/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Circle\n",
    "\n",
    "font1 = {'family':'serif','size':20}\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(20, 8))\n",
    "cf = ax.contourf(x, y, u, np.arange(-0.2, 1, .02), extend='both', cmap='rainbow')\n",
    "cbar = plt.colorbar(cf, pad=0.03, aspect=25, format='%.0e')\n",
    "# ax.plot([x.min(), x.max(), x.max(), x.min(), x.min()],\n",
    "#         [y.min(), y.min(), y.max(), y.max(), y.min()],\n",
    "#         color='black', linewidth=2, label='Domain Boundary')\n",
    "\n",
    "ax.add_patch(Circle((0.5, 0.5), 0.1, color=\"black\"))\n",
    "\n",
    "# Overlay cross-section lines\n",
    "for section in cross_sections:\n",
    "    section_type, value = section\n",
    "    if section_type == 'x':\n",
    "        ax.axvline(value, color='red', linestyle='--', linewidth=2, label=f'x={value}')\n",
    "    elif section_type == 'y':\n",
    "        ax.axhline(value, color='blue', linestyle='--', linewidth=2, label=f'y={value}')\n",
    "\n",
    "# Optional: avoid duplicate labels in legend\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "by_label = dict(zip(labels, handles))\n",
    "ax.legend(by_label.values(), by_label.keys(), fontsize=15)\n",
    "\n",
    "plt.title(\"u with Cross-Sections(Re-40)\", fontdict=font1)\n",
    "plt.xlabel(\"x\", fontdict=font1)\n",
    "plt.ylabel(\"y\", fontdict=font1)\n",
    "plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "cbar.ax.tick_params(labelsize=15)\n",
    "plt.savefig(\"u_with_cross_sections_40.png\", dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# ux_re10 = r\"C:\\Projects\\SoftwareLab_SS25\\Navier_Stokes_cylinder2D\\data\\Re10_Med_Ux\\Re10_Med_Ux_0.75.csv\"\n",
    "ux_re100 = r\"C:\\Projects\\SoftwareLab_SS25\\Navier_Stokes_cylinder2D\\data\\Re100_Med_Ux\\Re100_Med_Ux_0.75.csv\"\n",
    "# ux_re1000 = r\"C:\\Projects\\SoftwareLab_SS25\\Navier_Stokes_cylinder2D\\data\\Re1000_Med_Ux\\Re1000_Med_Ux_0.75.csv\"\n",
    "\n",
    "# Read CSVs (assume columns: arc_length, U_X)\n",
    "# df_re10 = pd.read_csv(ux_re10)\n",
    "df_re100 = pd.read_csv(ux_re100)\n",
    "# df_re1000 = pd.read_csv(ux_re1000)\n",
    "\n",
    "# Plot OpenFOAM velocity profiles at x=0.75 for different Reynolds numbers\n",
    "plt.figure(figsize=(8, 6))\n",
    "# plt.plot(df_re10[\"arc_length\"], df_re10[\"U_X\"], label=\"OpenFOAM Re=10\", color=\"green\", marker=\"o\")\n",
    "plt.plot(df_re100[\"arc_length\"], df_re100[\"U_X\"], label=\"OpenFOAM Re=100\", color=\"orange\", marker=\"^\")\n",
    "# plt.plot(df_re1000[\"arc_length\"], df_re1000[\"U_X\"], label=\"OpenFOAM Re=1000\", color=\"red\", marker=\"s\")\n",
    "plt.xlabel(\"y (arc length)\")\n",
    "plt.ylabel(\"u (velocity x)\")\n",
    "plt.title(\"OpenFOAM Velocity Profiles at x = 0.75\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "def plot_profile_comparison(y_pinn, u_pinn, y_ref, u_ref, label_pinn=\"PINN\", label_ref=\"OpenFOAM\", title=\"Velocity Profile Comparison\"):\n",
    "    \"\"\"\n",
    "    Plot and compare two velocity profiles along the same cross-section.\n",
    "    Args:\n",
    "        y_pinn: y-coordinates for PINN data.\n",
    "        u_pinn: velocity values for PINN data.\n",
    "        y_ref: y-coordinates for reference data (e.g., OpenFOAM).\n",
    "        u_ref: velocity values for reference data.\n",
    "        label_pinn: label for PINN data.\n",
    "        label_ref: label for reference data.\n",
    "        title: plot title.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(y_pinn, u_pinn, label=label_pinn, color='blue')\n",
    "    plt.plot(y_ref, u_ref, label=label_ref, color='orange')\n",
    "    plt.xlabel('y (arc length)')\n",
    "    plt.ylabel('u (velocity x)')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# List of cross-sections of interest\n",
    "cross_sections = [0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75]\n",
    "\n",
    "for x_target in cross_sections:\n",
    "    idx = np.argmin(np.abs(x[0, :] - x_target))\n",
    "    y_pinn = y[:, idx]\n",
    "    u_pinn = u[:, idx]\n",
    "    # Load OpenFOAM reference data for this cross-section\n",
    "    # Assumes file naming: data/Re10_cs/Re10_coarse_{x_target}.csv\n",
    "    fname = f\"data/Re40_coarse_cs/Re40_coarse_{x_target}.csv\"\n",
    "    try:\n",
    "        df_re = pd.read_csv(fname)\n",
    "        y_ref = df_re[\"arc_length\"]\n",
    "        u_ref = df_re[\"U_X\"]\n",
    "        plot_profile_comparison(\n",
    "            y_pinn, u_pinn, y_ref, u_ref,\n",
    "            label_pinn=\"PINN\",\n",
    "            label_ref=\"OpenFOAM\",\n",
    "            title=f\"RE:40, u Profile at x={x_target}\"\n",
    "        )\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Reference file not found: {fname}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "cross_sections = [0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7]\n",
    "fig, axes = plt.subplots(2, 5, figsize=(22, 8), sharey=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, x_target in enumerate(cross_sections):\n",
    "    idx = np.argmin(np.abs(x[0, :] - x_target))\n",
    "    y_pinn = y[:, idx]\n",
    "    u_pinn = u[:, idx]\n",
    "    fname = f\"../../data/Re40_coarse_cs/Re40_coarse_{x_target}.csv\"\n",
    "    try:\n",
    "        df_re = pd.read_csv(fname)\n",
    "        y_ref = df_re[\"arc_length\"]\n",
    "        u_ref = df_re[\"U_X\"]\n",
    "        axes[i].plot(y_pinn, u_pinn, label=\"PINN\", color='blue')\n",
    "        axes[i].plot(y_ref, u_ref, label=\"OpenFOAM\", color='orange')\n",
    "        axes[i].set_title(f\"x={x_target}\")\n",
    "        axes[i].set_xlabel(\"y\")\n",
    "        if i % 5 == 0:\n",
    "            axes[i].set_ylabel(\"u\")\n",
    "        axes[i].grid()\n",
    "        if i == 0:\n",
    "            axes[i].legend()\n",
    "    except FileNotFoundError:\n",
    "        axes[i].set_title(f\"x={x_target}\\nNo ref data\")\n",
    "        axes[i].set_xlabel(\"y\")\n",
    "        if i % 5 == 0:\n",
    "            axes[i].set_ylabel(\"u\")\n",
    "        axes[i].grid()\n",
    "\n",
    "plt.suptitle(\"Velocity Profile Comparison (PINN vs OpenFOAM)\", fontsize=18)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.savefig(\"profile_comparison_40.png\", dpi=300)  # Save as high-res image\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# y_pinn, u_pinn: PINN y and u values at x=0.75\n",
    "# y_ref, u_ref: OpenFOAM y and u values at x=0.75\n",
    "\n",
    "# Interpolate PINN profile onto OpenFOAM's y-coordinates\n",
    "u_pinn_interp = interp1d(y_pinn, u_pinn, kind='linear', bounds_error=False, fill_value='extrapolate')\n",
    "u_pinn_on_ref = u_pinn_interp(y_ref)\n",
    "\n",
    "# Compute errors\n",
    "mae = np.mean(np.abs(u_pinn_on_ref - u_ref))\n",
    "rmse = np.sqrt(np.mean((u_pinn_on_ref - u_ref)**2))\n",
    "\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "cross_sections = [0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75]\n",
    "results = []\n",
    "\n",
    "for x_target in cross_sections:\n",
    "    idx = np.argmin(np.abs(x[0, :] - x_target))\n",
    "    y_pinn = y[:, idx]\n",
    "    u_pinn = u[:, idx]\n",
    "    fname = f\"data/Re10_cs/Re10_coarse_{x_target}.csv\"\n",
    "    try:\n",
    "        df_re = pd.read_csv(fname)\n",
    "        y_ref = df_re[\"arc_length\"]\n",
    "        u_ref = df_re[\"U_X\"]\n",
    "        # Interpolate PINN profile onto OpenFOAM's y-coordinates\n",
    "        u_pinn_interp = interp1d(y_pinn, u_pinn, kind='linear', bounds_error=False, fill_value='extrapolate')\n",
    "        u_pinn_on_ref = u_pinn_interp(y_ref)\n",
    "        # Compute errors\n",
    "        mae = np.mean(np.abs(u_pinn_on_ref - u_ref))\n",
    "        rmse = np.sqrt(np.mean((u_pinn_on_ref - u_ref)**2))\n",
    "        results.append({'cs': x_target, 'mae': mae, 'rmse': rmse})\n",
    "    except FileNotFoundError:\n",
    "        results.append({'cs': x_target, 'mae': np.nan, 'rmse': np.nan})\n",
    "\n",
    "# Create and display table\n",
    "df_results = pd.DataFrame(results)\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_csv(\"data/Re40_coarse_errors.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pinnpy_3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
