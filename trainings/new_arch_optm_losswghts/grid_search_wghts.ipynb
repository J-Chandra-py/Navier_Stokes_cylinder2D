{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tf_silent\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from pinn import PINN\n",
    "from network import Network\n",
    "from optimizer import L_BFGS_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def u_0(xy):\n",
    "    \"\"\"\n",
    "    Initial wave form.\n",
    "    Args:\n",
    "        tx: variables (t, x) as tf.Tensor.\n",
    "    Returns:\n",
    "        u(t, x) as tf.Tensor.\n",
    "    \"\"\"\n",
    "\n",
    "    x = xy[..., 0, None]\n",
    "    y = xy[..., 1, None]\n",
    "\n",
    "\n",
    "    return    4*y*(1 - y) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "foam_df = pd.read_excel(\"/mnt/data_dzne_archiv2/Studien/Deep_Learning_Visualization/temporary_stuff/Jaya_Chandra_Terli/SS-2025/SLB-Project/Navier_Stokes_cylinder2D/data/Re40_Med_10k/foam_re40.xlsx\")\n",
    "\n",
    "# foam_df.head()\n",
    "foam_df['cx'] = foam_df['cx'].apply(lambda x: x+ 0.5)\n",
    "foam_df['cy'] = foam_df['cy'].apply(lambda x: x+ 0.5)\n",
    "# foam_df['U'] = foam_df['U'].apply(lambda x: x[0].split(' '))\n",
    "# foam_df.head()\n",
    "\n",
    "# Split U column into u, v (ignore the third value)\n",
    "foam_df[['u', 'v', '_']] = foam_df['U'].str.extract(r'\\(?\\s*([-\\d.eE]+)\\s+([-\\d.eE]+)\\s+([-\\d.eE]+)\\s*\\)?')\n",
    "foam_df['u'] = foam_df['u'].astype(float)\n",
    "foam_df['v'] = foam_df['v'].astype(float)\n",
    "foam_df['p'] = foam_df['p'].astype(float)\n",
    "\n",
    "# foam_df.head()\n",
    "x_of = foam_df['cx'].values\n",
    "y_of = foam_df['cy'].values\n",
    "u_of = foam_df['u'].values\n",
    "v_of = foam_df['v'].values\n",
    "p_of = foam_df['p'].values\n",
    "\n",
    "(x_of.dtype, x_of.shape), (y_of.dtype, y_of.shape), (u_of.dtype, u_of.shape), (v_of.dtype, v_of.shape), (p_of.dtype, p_of.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_xy_sel_with_domain(xy_sel, x_ini=0, x_f=2, y_ini=0, y_f=1, circle_center=(0.5, 0.5), circle_radius=0.1, title=\"xy_sel with Domain\"):\n",
    "    \"\"\"\n",
    "    Plot xy_sel points with rectangle domain and inner circle.\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib.patches import Rectangle, Circle\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    ax.scatter(xy_sel[:, 0], xy_sel[:, 1], s=5, c='blue', alpha=0.5, label=\"Selected Points\")\n",
    "    # Draw rectangle (domain)\n",
    "    rect = Rectangle((x_ini, y_ini), x_f - x_ini, y_f - y_ini, linewidth=2, edgecolor='black', facecolor='none', label=\"Domain\")\n",
    "    ax.add_patch(rect)\n",
    "    # Draw circle (obstacle)\n",
    "    # circle = Circle(circle_center, circle_radius, color='gray', fill=False, linestyle='--', linewidth=2, label=\"Cylinder\")\n",
    "    # ax.add_patch(circle)\n",
    "    ax.set_xlim(x_ini-0.1, x_f+0.1)\n",
    "    ax.set_ylim(y_ini-0.1, y_f+0.1)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_xlabel(\"x\")\n",
    "    ax.set_ylabel(\"y\")\n",
    "    ax.set_title(title)\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# plot_xy_sel_with_domain(xy_sel, title=\"Selected OpenFoam Points with Domain and Cylinder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "# Domain/cylinder parameters\n",
    "Cx, Cy = 0.5, 0.5\n",
    "a, b = 0.1, 0.1\n",
    "\n",
    "# 1. Annulus around cylinder (outer radius 0.25)\n",
    "num_annulus_samples = 1000\n",
    "theta = np.random.uniform(0, 2*np.pi, num_annulus_samples)\n",
    "r = np.sqrt(np.random.uniform(1, 6, num_annulus_samples)) * a  # sqrt for uniform area, scale for radius\n",
    "x_annulus = Cx + r * np.cos(theta)\n",
    "y_annulus = Cy + r * np.sin(theta)\n",
    "xyt_annulus = np.stack([x_annulus, y_annulus], axis=1)\n",
    "\n",
    "# 2. Wake region rectangle\n",
    "num_strip_samples = 1500\n",
    "x_strip = np.random.uniform(0.6, 1.2, num_strip_samples)\n",
    "y_strip = np.random.uniform(0.3, 0.7, num_strip_samples)\n",
    "xyt_strip = np.stack([x_strip, y_strip], axis=1)\n",
    "\n",
    "# 3. Uniform points elsewhere (excluding cylinder, annulus, and wake)\n",
    "\n",
    "num_uniform = 4000 - num_annulus_samples - num_strip_samples\n",
    "# xy_uniform = uniform_points_in_domain_exclusive(num_uniform)\n",
    "\n",
    "def uniform_points_in_domain(n_points, x_ini=0, x_f=2, y_ini=0, y_f=1, circle_center=(0.5, 0.5), circle_radius=0.1):\n",
    "    points = []\n",
    "    while len(points) < n_points:\n",
    "        x = np.random.uniform(x_ini, x_f)\n",
    "        y = np.random.uniform(y_ini, y_f)\n",
    "        if ((x - circle_center[0])**2 + (y - circle_center[1])**2) >= circle_radius**2:\n",
    "            points.append([x, y])\n",
    "    return np.array(points)\n",
    "\n",
    "xy_uniform = uniform_points_in_domain(num_uniform)\n",
    "\n",
    "# Combine all regions\n",
    "xyt_roi = np.concatenate([xyt_annulus, xyt_strip, xy_uniform], axis=0)\n",
    "\n",
    "mask_outside_cylinder = ((xyt_roi[:, 0] - Cx)**2 / a**2 + (xyt_roi[:, 1] - Cy)**2 / b**2) >= 1\n",
    "xyt_roi = xyt_roi[mask_outside_cylinder]\n",
    "\n",
    "# KDTree selection from OpenFOAM points\n",
    "coords_of = np.stack((x_of, y_of), axis=-1)\n",
    "tree = cKDTree(coords_of)\n",
    "_, indices = tree.query(xyt_roi, k=1)\n",
    "x_sel = x_of[indices]\n",
    "y_sel = y_of[indices]\n",
    "u_sel = u_of[indices]\n",
    "v_sel = v_of[indices]\n",
    "p_sel = p_of[indices]\n",
    "xy_sel = np.stack((x_sel, y_sel), axis=-1)\n",
    "\n",
    "# Plot to check\n",
    "plot_xy_sel_with_domain(xy_sel, title=\"Selected OpenFOAM Points: Annulus, Wake, Uniform\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uv_sel = np.stack((u_sel, v_sel, p_sel), axis=-1)\n",
    "uv_sel.shape, xy_sel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "\"\"\"\n",
    "Test the physics informed neural network (PINN) model\n",
    "for the cavity flow governed by the steady Navier-Stokes equation.\n",
    "\"\"\"\n",
    "\n",
    "# number of training samples\n",
    "num_train_samples = 4000\n",
    "# number of test samples\n",
    "num_test_samples = 200\n",
    "\n",
    "# inlet flow velocity\n",
    "u0 = 1\n",
    "# density\n",
    "rho = 1\n",
    "# viscosity\n",
    "mu = 0.025\n",
    "# Re = (L*u0*rho)/mu ==> rho/mu = 40\n",
    "\n",
    "# # build a core network model\n",
    "# network = Network().build()\n",
    "# network.summary()\n",
    "# # build a PINN model\n",
    "# pinn = PINN(network, rho=rho, mu=mu).build()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Domain and circle data\n",
    "x_f =2\n",
    "x_ini=0\n",
    "y_f=1\n",
    "y_ini=0\n",
    "Cx = 0.5\n",
    "Cy = 0.5\n",
    "a = 0.1\n",
    "b = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xyt_circle = np.random.rand(num_train_samples, 2)\n",
    "xyt_circle[...,0] = 2*(a)*xyt_circle[...,0] +(Cx-a)\n",
    "xyt_circle[0:num_train_samples//2,1] = b*(1 - (xyt_circle[0:num_train_samples//2,0]-Cx)**2 / a**2)**0.5 + Cy\n",
    "xyt_circle[num_train_samples//2:,1] = -b*(1 - (xyt_circle[num_train_samples//2:,0]-Cx)**2 / a**2)**0.5 + Cy\n",
    "\n",
    "# create training input\n",
    "xyt_eqn = np.random.rand(num_train_samples, 2)\n",
    "xyt_eqn[...,0] = (x_f - x_ini)*xyt_eqn[...,0] + x_ini\n",
    "xyt_eqn[...,1] = (y_f - y_ini)*xyt_eqn[...,1] + y_ini\n",
    "\n",
    "corner_buffer = 0.05\n",
    "max_attempts = 100\n",
    "\n",
    "for i in range(num_train_samples):\n",
    "    attempts = 0\n",
    "    while True:\n",
    "        inside_cylinder = (xyt_eqn[i, 0] - Cx)**2 / a**2 + (xyt_eqn[i, 1] - Cy)**2 / b**2 < 1\n",
    "        near_corner = (\n",
    "            (xyt_eqn[i, 0] < x_ini + corner_buffer and xyt_eqn[i, 1] < y_ini + corner_buffer) or\n",
    "            (xyt_eqn[i, 0] < x_ini + corner_buffer and xyt_eqn[i, 1] > y_f - corner_buffer) or\n",
    "            (xyt_eqn[i, 0] > x_f - corner_buffer and xyt_eqn[i, 1] < y_ini + corner_buffer) or\n",
    "            (xyt_eqn[i, 0] > x_f - corner_buffer and xyt_eqn[i, 1] > y_f - corner_buffer)\n",
    "        )\n",
    "\n",
    "        if not (inside_cylinder or near_corner):\n",
    "            break\n",
    "\n",
    "        xyt_eqn[i, 0] = (x_f - x_ini) * np.random.rand() + x_ini\n",
    "        xyt_eqn[i, 1] = (y_f - y_ini) * np.random.rand() + y_ini\n",
    "\n",
    "        attempts += 1\n",
    "        if attempts > max_attempts:\n",
    "            print(f\"Warning: Max attempts reached for sample {i}\")\n",
    "            break  # Accept the current (possibly imperfect) point or skip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- Plot training data distribution (separate plots, distinct markers) ---\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# def subsample(arr, max_points=2000):\n",
    "#     if arr.shape[0] > max_points:\n",
    "#         idx = np.random.choice(arr.shape[0], max_points, replace=False)\n",
    "#         return arr[idx]\n",
    "#     return arr\n",
    "\n",
    "# data_labels = [\n",
    "#     (\"PDE Interior\", xyt_eqn, 'blue', '.', 30)\n",
    "# ]\n",
    "\n",
    "# for label, data, color, marker, size in data_labels:\n",
    "#     arr = subsample(data)\n",
    "#     plt.figure(figsize=(15, 10))\n",
    "#     plt.scatter(arr[:, 0], arr[:, 1], s=size, c=color, alpha=0.7, marker=marker, label=label, edgecolors='none')\n",
    "#     plt.title(f\"Training Data: {label}\", fontsize=16)\n",
    "#     plt.xlabel('x')\n",
    "#     plt.ylabel('y')\n",
    "#     plt.xlim([0, 2])\n",
    "#     plt.ylim([0, 1])\n",
    "#     plt.gca().set_aspect('equal')\n",
    "#     plt.legend(loc='best', fontsize=12)\n",
    "#     # Draw cylinder for reference\n",
    "#     circle = plt.Circle((0.5, 0.5), 0.1, color='gray', fill=False, linestyle='--')\n",
    "#     plt.gca().add_patch(circle)\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xyt_w1 = np.random.rand(num_train_samples, 2)  # top-bottom boundaries\n",
    "xyt_w1[..., 0] = (x_f - x_ini)*xyt_w1[...,0] + x_ini\n",
    "xyt_w1[..., 1] =  y_ini          # y-position is 0 or 1\n",
    "\n",
    "xyt_w2 = np.random.rand(num_train_samples, 2)  # top-bottom boundaries\n",
    "xyt_w2[..., 0] = (x_f - x_ini)*xyt_w2[...,0] + x_ini\n",
    "xyt_w2[..., 1] =  y_f\n",
    "\n",
    "xyt_out = np.random.rand(num_train_samples, 2)  # left-right boundaries\n",
    "xyt_out[..., 0] = x_f\n",
    "\n",
    "xyt_in = np.random.rand(num_train_samples, 2)\n",
    "xyt_in[...,0] = x_ini\n",
    "\n",
    "x_train = [xy_sel, xyt_eqn, xyt_w1, xyt_w2, xyt_out, xyt_in, xyt_circle]\n",
    "\n",
    "# create training output\n",
    "zeros = np.zeros((num_train_samples, 3))\n",
    "#uv_bnd[..., 0] = -u0 * np.floor(xy_bnd[..., 0]) +1\n",
    "#ones = np.ones((num_train_samples, 3))\n",
    "#onze = np.random.rand(num_train_samples, 3)\n",
    "#onze[...,0] = u0\n",
    "#onze[...,1] = 0\n",
    "#onze[...,2] = u0\n",
    "a = u_0(tf.constant(xyt_in)).numpy()\n",
    "b = np.zeros((num_train_samples, 1))\n",
    "onze = np.random.permutation(np.concatenate([a,b,a],axis = -1))\n",
    "\n",
    "y_train = [uv_sel, zeros, onze, zeros, zeros, zeros, zeros]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training data shapes:\")\n",
    "print(\"Labels of x: (x_cord, y_cord), y: (u, v, p)\")\n",
    "for x, y in zip(x_train, y_train):\n",
    "    print(f\"Shape of x: {x.shape}, Shape of y: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_weights = [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Create folder if not exists\n",
    "os.makedirs('losstrails', exist_ok=True)\n",
    "\n",
    "factr_list = [1e3, 1e5, 1e7]\n",
    "m_list = [20, 30, 50]\n",
    "maxls_list = [20, 30, 50]\n",
    "\n",
    "results = []\n",
    "\n",
    "for factr_val in factr_list:\n",
    "    for m_val in m_list:\n",
    "        for maxls_val in maxls_list:\n",
    "            # Reset or rebuild your network and pinn here before training if needed\n",
    "            network = Network().build()\n",
    "            pinn = PINN(network, rho=rho, mu=mu).build()\n",
    "            \n",
    "            # Prepare training data as you do normally\n",
    "            # x_train, y_train, loss_weights are already defined or recreate here\n",
    "            \n",
    "            # Setup optimizer\n",
    "            lbfgs = L_BFGS_B(model=pinn, x_train=x_train, y_train=y_train,\n",
    "                             factr=factr_val, m=m_val, maxls=maxls_val,\n",
    "                             maxiter=30000, loss_weights=loss_weights)\n",
    "            \n",
    "            print(f\"Training with factr={factr_val}, m={m_val}, maxls={maxls_val}\")\n",
    "            lbfgs.fit()\n",
    "\n",
    "            # Save model and loss history\n",
    "            model_fname = f\"losstrails/model_m{m_val}_ls{maxls_val}_f{int(factr_val)}.h5\"\n",
    "            loss_fname = f\"losstrails/loss_m{m_val}_ls{maxls_val}_f{int(factr_val)}.json\"\n",
    "            \n",
    "            pinn.save(model_fname)\n",
    "            \n",
    "            with open(loss_fname, 'w') as f:\n",
    "                json.dump(lbfgs.loss_history, f)\n",
    "            \n",
    "            final_loss = lbfgs.loss_history[-1] if lbfgs.loss_history else None\n",
    "            \n",
    "            # Save results info\n",
    "            results.append({\n",
    "                'factr': factr_val,\n",
    "                'm': m_val,\n",
    "                'maxls': maxls_val,\n",
    "                'final_loss': final_loss,\n",
    "                'model_filename': model_fname,\n",
    "                'loss_filename': loss_fname\n",
    "            })\n",
    "\n",
    "# Save all results summary for easy reference\n",
    "with open('losstrails/training_summary.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "# Find best run\n",
    "best_run = min(results, key=lambda x: x['final_loss'])\n",
    "print(\"\\nBest Training Run:\")\n",
    "print(f\"factr: {best_run['factr']}\")\n",
    "print(f\"m: {best_run['m']}\")\n",
    "print(f\"maxls: {best_run['maxls']}\")\n",
    "print(f\"final_loss: {best_run['final_loss']}\")\n",
    "print(f\"model file: {best_run['model_filename']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1e2\n",
    "# Optimizer: L-BFGS-B (maxiter=30000)\n",
    "# L-BFGS-B:  22%|██▏       | 6611/30000 [14:11<50:13,  7.76iter/s, loss=0.127]\n",
    "\n",
    "# 1e3\n",
    "# Optimizer: L-BFGS-B (maxiter=30000)\n",
    "# L-BFGS-B:  26%|██▌       | 7772/30000 [15:55<45:31,  8.14iter/s, loss=0.13]\n",
    "\n",
    "# 1e5\n",
    "# Optimizer: L-BFGS-B (maxiter=30000)\n",
    "# L-BFGS-B:  14%|█▎        | 4103/30000 [10:12<1:04:23,  6.70iter/s, loss=0.128]\n",
    "\n",
    "# 1e7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(len(lbfgs_e4.loss_history)), np.log(lbfgs_e4.loss_history), label='Loss')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss vs. Iterations')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.savefig(\"loss_vs_iterations_re40e4_of_wl10cyl_losstrail.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_profiles(x, y, u, v, cross_sections, save_csv=False, prefix=\"u10\", location=\"data/pinn_profiles/\"):\n",
    "    \"\"\"\n",
    "    Plot velocity profiles (u, v) along specified cross-sections and optionally save u profiles to CSV.\n",
    "    Args:\n",
    "        x: x-array (meshgrid).\n",
    "        y: y-array (meshgrid).\n",
    "        u: u-array (velocity in x-direction).\n",
    "        v: v-array (velocity in y-direction).\n",
    "        cross_sections: List of cross-sections to plot. Each cross-section is a tuple (type, value).\n",
    "        save_csv: If True, save u profiles to CSV files.\n",
    "        prefix: Prefix for CSV filenames.\n",
    "    \"\"\"\n",
    "    for section in cross_sections:\n",
    "        section_type, value = section\n",
    "        if section_type == 'x':  # Vertical line (constant x)\n",
    "            idx = np.argmin(np.abs(x[0, :] - value))  # Find the closest x index\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.plot(y[:, idx], u[:, idx], label='u (x={})'.format(value))\n",
    "            plt.plot(y[:, idx], v[:, idx], label='v (x={})'.format(value))\n",
    "            plt.xlabel('y')\n",
    "            plt.ylabel('Velocity')\n",
    "            plt.title('Velocity Profiles at x = {}'.format(value))\n",
    "            plt.legend()\n",
    "            plt.grid()\n",
    "            plt.show()\n",
    "            if save_csv:\n",
    "                # Save u profile: y as 'x', u as 'u'\n",
    "                df = pd.DataFrame({'x': y[:, idx], 'u': u[:, idx]})\n",
    "                filename = f\"{prefix}_{value}.csv\"\n",
    "                df.to_csv(location+prefix+\"/\"+filename, index=False)\n",
    "        elif section_type == 'y':  # Horizontal line (constant y)\n",
    "            idx = np.argmin(np.abs(y[:, 0] - value))  # Find the closest y index\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.plot(x[idx, :], u[idx, :], label='u (y={})'.format(value))\n",
    "            plt.plot(x[idx, :], v[idx, :], label='v (y={})'.format(value))\n",
    "            plt.xlabel('x')\n",
    "            plt.ylabel('Velocity')\n",
    "            plt.title('Velocity Profiles at y = {}'.format(value))\n",
    "            plt.legend()\n",
    "            plt.grid()\n",
    "            plt.show()\n",
    "            if save_csv:\n",
    "                # Save u profile: x as 'x', u as 'u'\n",
    "                df = pd.DataFrame({'x': x[idx, :], 'u': u[idx, :]})\n",
    "                filename = f\"{prefix}_y{value}.csv\"\n",
    "                df.to_csv(location+prefix+\"/\"+filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create meshgrid coordinates (x, y) for test plots    \n",
    "# from utils import contour_neu as contour\n",
    "x = np.linspace(x_ini, x_f, 200)\n",
    "y = np.linspace(y_ini, y_f, 200)\n",
    "x, y = np.meshgrid(x, y)\n",
    "xy = np.stack([x.flatten(), y.flatten()], axis=-1)\n",
    "# predict (psi, p)\n",
    "# u_v_p = network.predict(xy, batch_size=len(xy))\n",
    "u_v_p = loaded_pinn.predict(xy, batch_size=len(xy))\n",
    "u, v, p = [ u_v_p[..., i].reshape(x.shape) for i in range(u_v_p.shape[-1]) ]\n",
    "# compute (u, v)\n",
    "u = u.reshape(x.shape)\n",
    "v = v.reshape(x.shape)\n",
    "p = p.reshape(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u.shape, v.shape, p.shape, x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contour(x, y, z, title, levels=200):\n",
    "    \"\"\"\n",
    "    Contour plot.\n",
    "    Args:\n",
    "        x: x-array.\n",
    "        y: y-array.\n",
    "        z: z-array.\n",
    "        title: title string.\n",
    "        levels: number of contour lines.\n",
    "        circle_center: (x, y) center of the circle.\n",
    "        circle_radius: radius of the circle.\n",
    "    \"\"\"\n",
    "    circle_center = (0.5, 0.5)\n",
    "    circle_radius = 0.1\n",
    "    vmin = np.min(z)\n",
    "    vmax = np.max(z)\n",
    "    font1 = {'family':'serif','size':20}\n",
    "    plt.contour(x, y, z, colors='k', linewidths=0.2, levels=levels)\n",
    "    plt.contourf(x, y, z, cmap='rainbow', levels=levels, norm=Normalize(vmin=vmin, vmax=vmax))\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect('equal')\n",
    "    circle = plt.Circle(circle_center, circle_radius, fc='black', zorder=10)\n",
    "    ax.add_patch(circle)\n",
    "    plt.title(title, fontdict=font1)\n",
    "    plt.xlabel(\"x\", fontdict=font1)\n",
    "    plt.ylabel(\"y\", fontdict=font1)\n",
    "    plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "    cbar = plt.colorbar(pad=0.03, aspect=25, format='%.0e')\n",
    "    cbar.mappable.set_clim(vmin, vmax)\n",
    "    cbar.ax.tick_params(labelsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plot test results\n",
    "fig = plt.figure(figsize=(16, 8))\n",
    "contour(x, y, p, 'p')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(16, 8))\n",
    "contour(x, y, u, 'u')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(16, 8))\n",
    "contour(x, y, v, 'v')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "###########################\n",
    "from matplotlib.patches import Circle\n",
    "font1 = {'family':'serif','size':20}\n",
    "\n",
    "fig0, ax0 = plt.subplots(1, 1,figsize=(20,8))\n",
    "cf0 = ax0.contourf(x, y, p, np.arange(-0.2, 1, .02),\n",
    "                extend='both',cmap='rainbow')\n",
    "cbar0 = plt.colorbar(cf0, pad=0.03, aspect=25, format='%.0e')\n",
    "plt.title(\"p\", fontdict = font1)\n",
    "plt.xlabel(\"x\", fontdict = font1)\n",
    "plt.ylabel(\"y\", fontdict = font1)\n",
    "ax0.add_patch(Circle((0.5, 0.5), 0.1,color=\"black\"))\n",
    "plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "cbar0.ax.tick_params(labelsize=15)\n",
    "plt.show()\n",
    "\n",
    "###########################\n",
    "\n",
    "fig0, ax0 = plt.subplots(1, 1, figsize=(20,8))\n",
    "cf0 = ax0.contourf(x, y, u, np.arange(-0.5, 1.1, .02),\n",
    "                extend='both',cmap='rainbow')\n",
    "cbar0 = plt.colorbar(cf0, )\n",
    "plt.title(\"u\", fontdict = font1)\n",
    "plt.xlabel(\"x\", fontdict = font1)\n",
    "plt.ylabel(\"y\", fontdict = font1)\n",
    "ax0.add_patch(Circle((0.5, 0.5), 0.1,color=\"black\"))\n",
    "plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "cbar0.ax.tick_params(labelsize=15)\n",
    "plt.show()\n",
    "\n",
    "###########################\n",
    "\n",
    "fig0, ax0 = plt.subplots(1, 1,figsize=(20,8))\n",
    "cf0 = ax0.contourf(x, y, v, np.arange(-0.4, 0.4, .02),\n",
    "                extend='both',cmap='rainbow')\n",
    "cbar0 = plt.colorbar(cf0, pad=0.03, aspect=25, format='%.0e')\n",
    "plt.title(\"v\", fontdict = font1)\n",
    "plt.xlabel(\"x\", fontdict = font1)\n",
    "plt.ylabel(\"y\", fontdict = font1)\n",
    "ax0.add_patch(Circle((0.5, 0.5), 0.1,color=\"black\"))\n",
    "plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "cbar0.ax.tick_params(labelsize=15)\n",
    "plt.show()\n",
    "\n",
    "############################ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Circle\n",
    "\n",
    "font1 = {'family':'serif','size':20}\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(20, 8))\n",
    "# Contourf for pressure (or any scalar field)\n",
    "# cf = ax.contourf(x, y, u, np.arange(-0.2, 1, .02), extend='both', cmap='rainbow')\n",
    "# cbar = plt.colorbar(cf, pad=0.03, aspect=25, format='%.0e')\n",
    "# Streamlines for velocity field\n",
    "strm = ax.streamplot(x, y, u, v, color='k', density=5, linewidth=0.25)\n",
    "# Add cylinder\n",
    "ax.add_patch(Circle((0.5, 0.5), 0.1, color=\"black\"))\n",
    "plt.title(\"Re40: Streamlines & weighted loss - Cylinder wall\", fontdict=font1)\n",
    "plt.xlabel(\"x\", fontdict=font1)\n",
    "plt.ylabel(\"y\", fontdict=font1)\n",
    "plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "# cbar.ax.tick_params(labelsize=15)\n",
    "# plt.savefig('u_streamlines_Re40_of_roie5_wl10cyl.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(20, 8))\n",
    "\n",
    "# Streamlines for velocity field\n",
    "strm = ax.streamplot(x, y, u, v, color='k', density=5, linewidth=0.25)\n",
    "# Add cylinder\n",
    "ax.add_patch(Circle((0.5, 0.5), 0.1, color=\"black\"))\n",
    "plt.title(\"Re40: Streamlines & weighted loss - Cylinder wall\", fontdict=font1)\n",
    "plt.xlabel(\"x\", fontdict=font1)\n",
    "plt.ylabel(\"y\", fontdict=font1)\n",
    "plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "# plt.savefig('u_streamlines_Re40_of_roie5_wl10cyl.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot velocity profiles along specified cross-sections\n",
    "import pandas as pd\n",
    "cross_sections = [\n",
    "    ('x', 0.30),\n",
    "    ('x', 0.35),\n",
    "    ('x', 0.40),\n",
    "    ('x', 0.45),\n",
    "    ('x', 0.50),\n",
    "    ('x', 0.55),\n",
    "    ('x', 0.60),\n",
    "    ('x', 0.65),\n",
    "    ('x', 0.70),\n",
    "    ('x', 0.75),\n",
    "]\n",
    "plot_profiles(x, y, u, v, cross_sections, save_csv=False, prefix=\"u40_ofwl_roie5\", location=\"../../data/pinn_profiles/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "def plot_profile_comparison(y_pinn, u_pinn, y_ref, u_ref, label_pinn=\"PINN\", label_ref=\"OpenFOAM\", title=\"Velocity Profile Comparison\"):\n",
    "    \"\"\"\n",
    "    Plot and compare two velocity profiles along the same cross-section.\n",
    "    Args:\n",
    "        y_pinn: y-coordinates for PINN data.\n",
    "        u_pinn: velocity values for PINN data.\n",
    "        y_ref: y-coordinates for reference data (e.g., OpenFOAM).\n",
    "        u_ref: velocity values for reference data.\n",
    "        label_pinn: label for PINN data.\n",
    "        label_ref: label for reference data.\n",
    "        title: plot title.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(y_pinn, u_pinn, label=label_pinn, color='blue')\n",
    "    plt.plot(y_ref, u_ref, label=label_ref, color='orange')\n",
    "    plt.xlabel('y (arc length)')\n",
    "    plt.ylabel('u (velocity x)')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# List of cross-sections of interest\n",
    "cross_sections = [0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75]\n",
    "\n",
    "for x_target in cross_sections:\n",
    "    idx = np.argmin(np.abs(x[0, :] - x_target))\n",
    "    y_pinn = y[:, idx]\n",
    "    u_pinn = u[:, idx]\n",
    "    # Load OpenFOAM reference data for this cross-section\n",
    "    # Assumes file naming: data/Re10_cs/Re10_coarse_{x_target}.csv\n",
    "    fname = f\"../../data/Re40_coarse_cs/Re40_coarse_{x_target}.csv\"\n",
    "    try:\n",
    "        df_re = pd.read_csv(fname)\n",
    "        y_ref = df_re[\"arc_length\"]\n",
    "        u_ref = df_re[\"U_X\"]\n",
    "        plot_profile_comparison(\n",
    "            y_pinn, u_pinn, y_ref, u_ref,\n",
    "            label_pinn=\"PINN\",\n",
    "            label_ref=\"OpenFOAM\",\n",
    "            title=f\"RE:40, u Profile at x={x_target}\"\n",
    "        )\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Reference file not found: {fname}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# y_pinn, u_pinn: PINN y and u values at x=0.75\n",
    "# y_ref, u_ref: OpenFOAM y and u values at x=0.75\n",
    "\n",
    "# Interpolate PINN profile onto OpenFOAM's y-coordinates\n",
    "u_pinn_interp = interp1d(y_pinn, u_pinn, kind='linear', bounds_error=False, fill_value='extrapolate')\n",
    "u_pinn_on_ref = u_pinn_interp(y_ref)\n",
    "\n",
    "# Compute errors\n",
    "mae = np.mean(np.abs(u_pinn_on_ref - u_ref))\n",
    "rmse = np.sqrt(np.mean((u_pinn_on_ref - u_ref)**2))\n",
    "\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbfgs.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from layer import GradientLayer\n",
    "\n",
    "loaded_pinn = load_model(\"pinn_dummysave.h5\", custom_objects={'GradientLayer': GradientLayer})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_config(self):\n",
    "#         config = super().get_config()\n",
    "#         config.update({\n",
    "#             \"arg1\": self.arg1,\n",
    "#             \"arg2\": self.arg2,\n",
    "#         })\n",
    "#         return config"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pinnpy3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
